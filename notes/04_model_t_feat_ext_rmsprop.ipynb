{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Model T - Transfer Learning, Feature Extraction, RMSProp\n",
    "- **128 x 128** x 3 Image size.  \n",
    "- **64** Batch size.  \n",
    "- **VGG16** Convolutional Base.\n",
    "- **Feature Extraction**.  \n",
    "- **Root Mean Square Propagation (RMSProp)** optimizer.\n",
    "- **4 x 4 x 512** Tensor before flatten.  \n",
    "- **Classifier**: \n",
    "    - 512 Dense layer with **ReLU** activation function and **L1L2** regularization.\n",
    "    - Root Mean Square Propagation **(RMSProp) optimizer** with 0.001 Learning Rate.  \n",
    "    - **30 Epochs** to train the classifier.  \n",
    "- Build the **full model** and test it."
   ],
   "id": "8f90eceeed232e54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Imports and Setup"
   ],
   "id": "c6735bde07639ba2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T19:26:46.611189Z",
     "start_time": "2024-06-07T19:26:44.681980Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, optimizers, models\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay ,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We resize the images to **128 x 128** pixels.  \n",
    "- With this image size, we expect a **4 x 4 x 512** feature map after the convolutional base.  "
   ],
   "id": "1a9991ed0da93f8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Group Datasets"
   ],
   "id": "3bd6072b1d12d0b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:26:46.616095Z",
     "start_time": "2024-06-07T19:26:46.612602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "train_dirs = [f'../data/train1_resized_{IMG_SIZE}', f'../data/train3_resized_{IMG_SIZE}', f'../data/train4_resized_{IMG_SIZE}', f'../data/train5_resized_{IMG_SIZE}']\n",
    "validation_dir = f'../data/train2_resized_{IMG_SIZE}'\n",
    "test_dir = f'../data/test_resized_{IMG_SIZE}'"
   ],
   "id": "f972b55051087b5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- ((2221985 + 2221986) % 5) + 1 = 2  \n",
    "- **Validation set: train2**.  "
   ],
   "id": "5af858988eb26fa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Create Datasets"
   ],
   "id": "dfc2bfc04e619b7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:26:50.604869Z",
     "start_time": "2024-06-07T19:26:46.617318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "train_datasets = [image_dataset_from_directory(directory, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE) for directory in train_dirs]\n",
    "\n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "class_names = train_datasets[0].class_names\n",
    "\n",
    "for data_batch, labels_batch in train_dataset.take(1):\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)"
   ],
   "id": "d699b2929af3e6b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "data batch shape: (64, 128, 128, 3)\n",
      "labels batch shape: (64,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We define the batch size of 64 and create an array with the label's names.  \n",
    "- We create the train dataset by concatenating them, we **shuffle** the samples before each epoch and **prefetch** them to memory.  \n",
    "- We do the same for the validation and test dataset except shuffling which is unnecessary."
   ],
   "id": "d7988a1b1bf91e80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Loading the VGG16 Model"
   ],
   "id": "d1a35d3cdfbf44a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:26:54.092715Z",
     "start_time": "2024-06-07T19:26:50.605956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "conv_base.summary()"
   ],
   "id": "7cea8386294502c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We load the VGG16 model with the imagenet weights, without the top layer and with the input shape of 128 x 128 pixels and 3 channels.",
   "id": "6f3271d7ffe978de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Feature Extraction"
   ],
   "id": "ee9c27df5d07cb6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:45:09.634692Z",
     "start_time": "2024-06-07T19:26:54.094300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "val_features, val_labels = get_features_and_labels(validation_dataset)"
   ],
   "id": "47dfb1365748d332",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 623ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 620ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 620ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 631ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 617ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 627ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 623ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 618ms/step\n",
      "2/2 [==============================] - 1s 620ms/step\n",
      "2/2 [==============================] - 1s 618ms/step\n",
      "2/2 [==============================] - 1s 620ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 621ms/step\n",
      "2/2 [==============================] - 1s 622ms/step\n",
      "2/2 [==============================] - 1s 623ms/step\n",
      "2/2 [==============================] - 1s 636ms/step\n",
      "2/2 [==============================] - 1s 776ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 679ms/step\n",
      "2/2 [==============================] - 1s 676ms/step\n",
      "2/2 [==============================] - 1s 678ms/step\n",
      "2/2 [==============================] - 1s 677ms/step\n",
      "2/2 [==============================] - 1s 679ms/step\n",
      "2/2 [==============================] - 1s 676ms/step\n",
      "2/2 [==============================] - 1s 676ms/step\n",
      "2/2 [==============================] - 1s 677ms/step\n",
      "2/2 [==============================] - 1s 678ms/step\n",
      "2/2 [==============================] - 1s 677ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 677ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 672ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 678ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 674ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 673ms/step\n",
      "2/2 [==============================] - 1s 672ms/step\n",
      "2/2 [==============================] - 1s 677ms/step\n",
      "2/2 [==============================] - 1s 675ms/step\n",
      "2/2 [==============================] - 1s 705ms/step\n",
      "2/2 [==============================] - 2s 719ms/step\n",
      "2/2 [==============================] - 1s 712ms/step\n",
      "2/2 [==============================] - 1s 709ms/step\n",
      "2/2 [==============================] - 1s 707ms/step\n",
      "2/2 [==============================] - 1s 701ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 680ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 680ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 695ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 706ms/step\n",
      "2/2 [==============================] - 1s 729ms/step\n",
      "2/2 [==============================] - 1s 711ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 699ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 708ms/step\n",
      "2/2 [==============================] - 1s 730ms/step\n",
      "2/2 [==============================] - 1s 704ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 694ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 699ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 691ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 719ms/step\n",
      "2/2 [==============================] - 1s 728ms/step\n",
      "2/2 [==============================] - 1s 717ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 694ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 707ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 694ms/step\n",
      "2/2 [==============================] - 1s 721ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 681ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 703ms/step\n",
      "2/2 [==============================] - 1s 726ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 700ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 700ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 716ms/step\n",
      "2/2 [==============================] - 1s 711ms/step\n",
      "2/2 [==============================] - 1s 731ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 707ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 704ms/step\n",
      "2/2 [==============================] - 1s 727ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 695ms/step\n",
      "2/2 [==============================] - 1s 696ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 720ms/step\n",
      "2/2 [==============================] - 1s 727ms/step\n",
      "2/2 [==============================] - 1s 718ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 692ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 701ms/step\n",
      "2/2 [==============================] - 1s 725ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 702ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 697ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 712ms/step\n",
      "2/2 [==============================] - 1s 724ms/step\n",
      "2/2 [==============================] - 1s 708ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 701ms/step\n",
      "2/2 [==============================] - 1s 723ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 697ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 713ms/step\n",
      "2/2 [==============================] - 1s 726ms/step\n",
      "2/2 [==============================] - 1s 712ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 705ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 689ms/step\n",
      "2/2 [==============================] - 1s 722ms/step\n",
      "2/2 [==============================] - 1s 700ms/step\n",
      "2/2 [==============================] - 1s 711ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 692ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 716ms/step\n",
      "2/2 [==============================] - 1s 714ms/step\n",
      "2/2 [==============================] - 1s 724ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 705ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 758ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 688ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 696ms/step\n",
      "2/2 [==============================] - 1s 727ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 687ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 690ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 686ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 685ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 682ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 684ms/step\n",
      "2/2 [==============================] - 1s 683ms/step\n",
      "2/2 [==============================] - 1s 714ms/step\n",
      "2/2 [==============================] - 1s 723ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We extract the features from the convolutional base of the VGG16 model for the train and validation dataset.\n",
    "- We don't need to extract the features from the test dataset because we will use the full model to predict it."
   ],
   "id": "926ddd37df4e2b55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Saving the features and labels"
   ],
   "id": "b4b708d40c757eae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:45:10.374874Z",
     "start_time": "2024-06-07T19:45:09.635730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.save('../features/04_model_t_feat_ext_rmsprop_train_features.npy', train_features)\n",
    "np.save('../features/04_model_t_feat_ext_rmsprop_train_labels.npy', train_labels)\n",
    "np.save('../features/04_model_t_feat_ext_rmsprop_val_features.npy', val_features)\n",
    "np.save('../features/04_model_t_feat_ext_rmsprop_val_labels.npy', val_labels)"
   ],
   "id": "8cddbab9b1f6814d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Loading the features and labels"
   ],
   "id": "4de28ec4aa964a60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:45:10.611938Z",
     "start_time": "2024-06-07T19:45:10.375751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = np.load('../features/04_model_t_feat_ext_rmsprop_train_features.npy')\n",
    "train_labels = np.load('../features/04_model_t_feat_ext_rmsprop_train_labels.npy')\n",
    "val_features = np.load('../features/04_model_t_feat_ext_rmsprop_val_features.npy')\n",
    "val_labels = np.load('../features/04_model_t_feat_ext_rmsprop_val_labels.npy')"
   ],
   "id": "6df1aff1d8c36076",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Classifier Arquitecture"
   ],
   "id": "e1295d3f549e2bcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:45:10.651853Z",
     "start_time": "2024-06-07T19:45:10.612718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = keras.Input(shape=(4, 4, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.L2(1e-4))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", kernel_regularizer=regularizers.L2(1e-4))(x)\n",
    "classifier = models.Model(inputs=inputs, outputs=outputs)\n",
    "classifier.summary()"
   ],
   "id": "83b92ce40cddb3b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 4, 4, 512)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4199946 (16.02 MB)\n",
      "Trainable params: 4199946 (16.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Input size of 4 x 4 x 512.  \n",
    "- Flatten the tensor to a 8192 x 1 tensor. \n",
    "- A 512 and 10 dense output layer, one for each category. \n",
    "- Dropout of 0.5 before the dense layers.\n",
    "- L1 regularization 0.0001 and L2 regularization 0.001 on the dense layers.    \n",
    "- ReLU activation function on the dense layer.  \n",
    "- Softmax activation function on the output layer for multiclass classification.  "
   ],
   "id": "759006a6d6fc081a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Compilation"
   ],
   "id": "b91ca83987f82a9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:45:10.662827Z",
     "start_time": "2024-06-07T19:45:10.652618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_learning_rate = 0.0001\n",
    "optimizer = optimizers.RMSprop(learning_rate=initial_learning_rate)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
    "save_best_model = callbacks.ModelCheckpoint(filepath='../models/04_model_t_feat_ext_rmsprop_classifier.keras', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, early_stopping, save_best_model]\n",
    "\n",
    "classifier.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ],
   "id": "6a604147d46665f1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **RMSProp** as the optimizer for this model with an initial learning rate of 0.001.  \n",
    "- **Sparse categorical cross entropy** as the loss function, because our labels are not one hot encoded.  \n",
    "- **Learning rate scheduler** to lower the learning rate by a factor of 0.1 on validation loss plateau (patience of 2).  \n",
    "- **Early train stopping** based on validation loss improvement (stops when validation loss doesn't improve for 4 straight epochs (patience of 4)).  \n",
    "- **Checkpoints** to save the best model between each epoch based on validation loss."
   ],
   "id": "3d29c779bb675e70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Training\n",
    "- We train the classifier with the extracted features during 30 epochs."
   ],
   "id": "1561b6b62a6a19e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:30.203213Z",
     "start_time": "2024-06-07T19:45:10.663588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = classifier.fit(train_features,\n",
    "                    train_labels,\n",
    "                    epochs=30,\n",
    "                    validation_data=(val_features, val_labels),\n",
    "                    callbacks=callbacks)"
   ],
   "id": "7c7803fd68bb2466",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 3.9338 - accuracy: 0.6455\n",
      "Epoch 1: val_loss improved from inf to 0.64834, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 25s 19ms/step - loss: 3.9333 - accuracy: 0.6454 - val_loss: 0.6483 - val_accuracy: 0.8263 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.3337 - accuracy: 0.7573\n",
      "Epoch 2: val_loss improved from 0.64834 to 0.57910, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.3330 - accuracy: 0.7574 - val_loss: 0.5791 - val_accuracy: 0.8459 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 1.0927 - accuracy: 0.7964\n",
      "Epoch 3: val_loss improved from 0.57910 to 0.54212, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 1.0931 - accuracy: 0.7964 - val_loss: 0.5421 - val_accuracy: 0.8626 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.8203\n",
      "Epoch 4: val_loss improved from 0.54212 to 0.53576, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9704 - accuracy: 0.8204 - val_loss: 0.5358 - val_accuracy: 0.8695 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.9021 - accuracy: 0.8349\n",
      "Epoch 5: val_loss improved from 0.53576 to 0.52874, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.9020 - accuracy: 0.8349 - val_loss: 0.5287 - val_accuracy: 0.8745 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.8453\n",
      "Epoch 6: val_loss did not improve from 0.52874\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.8313 - accuracy: 0.8453 - val_loss: 0.5301 - val_accuracy: 0.8774 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7822 - accuracy: 0.8564\n",
      "Epoch 7: val_loss did not improve from 0.52874\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.7821 - accuracy: 0.8565 - val_loss: 0.5421 - val_accuracy: 0.8798 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.7565 - accuracy: 0.8647\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.52874\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.7562 - accuracy: 0.8647 - val_loss: 0.5385 - val_accuracy: 0.8845 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.8738\n",
      "Epoch 9: val_loss did not improve from 0.52874\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6723 - accuracy: 0.8738 - val_loss: 0.5315 - val_accuracy: 0.8866 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6830 - accuracy: 0.8740\n",
      "Epoch 10: val_loss improved from 0.52874 to 0.52820, saving model to ../models/04_model_t_feat_ext_rmsprop_classifier.keras\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6828 - accuracy: 0.8741 - val_loss: 0.5282 - val_accuracy: 0.8878 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6530 - accuracy: 0.8777\n",
      "Epoch 11: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6530 - accuracy: 0.8777 - val_loss: 0.5305 - val_accuracy: 0.8873 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6512 - accuracy: 0.8796\n",
      "Epoch 12: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6509 - accuracy: 0.8796 - val_loss: 0.5343 - val_accuracy: 0.8870 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6479 - accuracy: 0.8805\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6477 - accuracy: 0.8805 - val_loss: 0.5335 - val_accuracy: 0.8885 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6406 - accuracy: 0.8805\n",
      "Epoch 14: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.6402 - accuracy: 0.8806 - val_loss: 0.5326 - val_accuracy: 0.8883 - lr: 1.0000e-06\n",
      "Epoch 15/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.8825\n",
      "Epoch 15: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6380 - accuracy: 0.8824 - val_loss: 0.5319 - val_accuracy: 0.8883 - lr: 1.0000e-06\n",
      "Epoch 16/30\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.6262 - accuracy: 0.8826\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.52820\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.6263 - accuracy: 0.8825 - val_loss: 0.5320 - val_accuracy: 0.8884 - lr: 1.0000e-06\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Save Model History"
   ],
   "id": "c1414fc4bf4495f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:30.206057Z",
     "start_time": "2024-06-07T19:51:30.203966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"../history/04_model_t_feat_ext_rmsprop_classifier.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "id": "f5ee8f1b7a93d59b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Classifier Evaluation"
   ],
   "id": "75ab7a00cecd12d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:31.105727Z",
     "start_time": "2024-06-07T19:51:30.206748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_loss, val_acc = classifier.evaluate(val_features, val_labels)\n",
    "print(f'Classifier Validation Loss: {val_loss:.2f}')\n",
    "print(f'Classifier Validation Accuracy: {val_acc:.2%}')"
   ],
   "id": "119ca4b48e11020d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.8878\n",
      "Classifier Validation Loss: 0.53\n",
      "Classifier Validation Accuracy: 88.78%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Training Visualization"
   ],
   "id": "3e06235a110145b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:31.365625Z",
     "start_time": "2024-06-07T19:51:31.106497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b82798d66c269136",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Analyzing the training and validation accuracy and loss over the epochs:\n",
    "    - We see that the model begins slightly overfitting after the **15th** epoch. The validation accuracy stops improving significantly while the training accuracy keeps improving.  \n",
    "    - The validation loss stops improving significantly after the **15th** epoch while the training loss keeps improving. \n",
    "    - The best model, based on validation loss, is saved on the **20th** epoch.   "
   ],
   "id": "3b28b2e5a426f333"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Building the full model (VGG16 + Classifier)"
   ],
   "id": "785d605186464885"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T19:51:31.871252Z",
     "start_time": "2024-06-07T19:51:31.367399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = keras.applications.vgg16.preprocess_input(inputs)\n",
    "x = conv_base(x)\n",
    "outputs = classifier(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "model.save('../models/04_model_t_feat_ext_rmsprop_full_model.h5')"
   ],
   "id": "1118d33fd14f9079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 128, 128, 3)       0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda  (None, 128, 128, 3)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " model (Functional)          (None, 10)                4199946   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18914634 (72.15 MB)\n",
      "Trainable params: 18914634 (72.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot serialize object Ellipsis of type <class 'ellipsis'>. To be serializable, a class must implement the `get_config()` method.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 13\u001B[0m\n\u001B[1;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      8\u001B[0m     loss\u001B[38;5;241m=\u001B[39mloss_function,\n\u001B[1;32m      9\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39moptimizer,\n\u001B[1;32m     10\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../models/04_model_t_feat_ext_rmsprop_full_model.keras\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/saving/serialization_lib.py:395\u001B[0m, in \u001B[0;36m_get_class_or_fn_config\u001B[0;34m(obj)\u001B[0m\n\u001B[1;32m    393\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m object_registration\u001B[38;5;241m.\u001B[39mget_registered_name(obj)\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 395\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    396\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot serialize object \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    397\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo be serializable, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    398\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma class must implement the `get_config()` method.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    399\u001B[0m     )\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot serialize object Ellipsis of type <class 'ellipsis'>. To be serializable, a class must implement the `get_config()` method."
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- We join the VGG16 convolutional base with our classifier trained with the extracted features, compile it, and save it.",
   "id": "76348bf6eb672a5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Testing"
   ],
   "id": "d2409d0121f3719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels = []\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    test_labels.extend(labels.numpy())\n",
    "    predictions = model.predict(images)\n",
    "    test_predictions.extend(np.argmax(predictions, axis=-1))\n",
    "    test_probabilities.extend(predictions)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_probabilities = np.array(test_probabilities)"
   ],
   "id": "85b3f7b2aa7331fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Confusion Matrix"
   ],
   "id": "fca30daa6d2c5258"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.show()"
   ],
   "id": "4be6a931c81836a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the confusion matrix, we see that the model has some trouble distinguishing between some categories.  \n",
    "- The model has a hard time distinguishing between the categories 003_cat and 005_dog.  \n",
    "- The model also has a hard time distinguishing between some other categories but the error is not as significant.  \n",
    "- The model has an acceptable performance on the categories 000_airplane, 001_automobile, 004_deer, 006_frog, 007_horse, 008_ship and 009_truck."
   ],
   "id": "8a3e816c5c8fe13a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### ROC Curve Analysis"
   ],
   "id": "e68c9fb0e696ac86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels_bin = label_binarize(test_labels, classes=range(NUM_CLASSES))\n",
    "\n",
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    false_positive_rate[i], true_positive_rate[i], _ = roc_curve(test_labels_bin[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(false_positive_rate[i], true_positive_rate[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'brown', 'pink', 'grey'])\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(false_positive_rate[i], true_positive_rate[i], color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "b8f0a28c2c459ae9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We see that the model has a good performance on the ROC curve for most categories.  \n",
    "- The categories 003_cat, 003_bird, 005_dog and 004_deer have the worst AUC (Area Under Curve) performance.\n",
    "- A perfect AUC of 1.0 would mean that the model classifies all true positives and true negatives correctly."
   ],
   "id": "713c306fcd31d921"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Performance Metrics\n",
    "- **Accuracy** is the proportion of correctly predicted instances out of the total instances.  \n",
    "- **Precision** is the ratio of true positive predictions to the total predicted positives. Macro precision calculates this for each class independently and then averages them.  \n",
    "- **Weighted precision** calculates the precision for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- **Recall** is the ratio of true positive predictions to the total actual positives. Macro recall calculates this for each class independently and then averages them.  \n",
    "- **Weighted recall** calculates the recall for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- The **F1-score** is the harmonic mean of precision and recall. Macro F1-score calculates this for each class independently and then averages them.  \n",
    "- **Weighted F1-score** calculates the F1-score for each class, then averages them, weighted by the number of true instances for each class.  "
   ],
   "id": "e8c8ee6e74938bdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = accuracy_score(y_true =  test_labels, y_pred = test_predictions)\n",
    "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Precision - Macro: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Recall - Macro: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'F1-score - Macro: {np.round(f1*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Precision - Weighted: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Recall - Weighted: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'F1-score - Weighted: {np.round(f1*100,2)}%')"
   ],
   "id": "479b290df6a7c03b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- **Since the dataset is balanced, the **MACRO** average is a good metric to evaluate the model.**",
   "id": "a153655cd9046d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "- We resized our images to be the 128 x 128.\n",
    "- We extracted feature maps from our datasets using the convolutional base of the VGG16.\n",
    "- We have trained a classifier with those extracted features.  \n",
    "- We experimented with various classifier architectures, and we settled for this one, keeping input size to 128 x 128 and our classifier with a 512 dense layer.  \n",
    "     - Different learning rates were tested; we settled for the Reduce Learning Rate on Plateau callback with a starting value of 0.001.\n",
    "    - Various batch sizes were explored; this size was optimal for this architecture.  \n",
    "    - Multiple optimizers were evaluated; we settled for RMSProp.\n",
    "    - Several regularization values were tried; these values worked best.\n",
    "    - Different dropout rates were assessed; this rate provided the best results.\n",
    "    - Various epoch counts were tested; 30 epochs were optimal.\n",
    "    - We used L1 and L2 regularization on the classifier.\n",
    "    - Dropout was applied to the input layer and the dense layer.\n",
    "- The model showed some difficulty distinguishing between certain categories, particularly cats and dogs.\n",
    "- Overfitting was observed after **15 epochs**, but the best model was saved at the **20th epoch**.\n",
    "- We evaluated the model using a confusion matrix to analyze its performance on each category.\n",
    "- We evaluated the model using ROC curves for a deeper performance analysis.\n",
    "- **The model achieved an accuracy of 81.83% on the test set**.\n",
    "- Performance on the test set was good, with:\n",
    "    - Macro F1-score: 89.29%\n",
    "    - Weighted F1-score: 89.29%\n",
    "    - Macro precision: 89.32%\n",
    "    - Weighted precision: 89.32%\n",
    "    - Macro recall: 89.29%\n",
    "    - Weighted recall: 89.29%\n",
    "\n",
    "### Future Work\n",
    "- In the next phase, we will:\n",
    "    - Implement and test transfer learning with the VGG16 convolutional base and our classifier along with fine-tuning by later unfreezing some of the VGG16 layers to further improve model generalization.\n",
    "    - Experiment with data augmentation to improve model generalization.\n",
    "    - Explore additional regularization methods to address overfitting."
   ],
   "id": "9d23124cf3831d1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
