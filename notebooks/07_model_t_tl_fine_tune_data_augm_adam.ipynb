{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Model T - Transfer Learning, Feature Extraction, Data Augmentation, Adaptive Moment Estimation (Adam)\n",
    "- **128 x 128 x 3** Image size.  \n",
    "- **64** Batch size.\n",
    "- Build the **full model** with **VGG16** convolutional base and a **Classifier**.\n",
    "    - **Data Augmentation Pipeline**\n",
    "        - Random **Horizontal** Flip\n",
    "        - Random Rotation **5%**\n",
    "        - Random Zoom **5%**\n",
    "        - Random Contrast **5%**\n",
    "        - Random Brightness **5%**\n",
    "    - **Feature Extraction**.\n",
    "        - **VGG16** Convolutional Base **(Frozen)**.\n",
    "        - **4 x 4 x 512** Feature Maps.\n",
    "    - **Classifier**: \n",
    "        - Adaptive Moment Estimation **(Adam)** optimizer.\n",
    "        - **0.001** Initial Learning rate.\n",
    "        - **Sparse Categorical Cross-Entropy** loss function.\n",
    "        - **Reduce Learning Rate on Plateau** callback with a **0.1** factor and **3** patience.\n",
    "        - **Early Stopping** callback with **6** patience.\n",
    "        - **Model Checkpoint** callback to save the best model based on validation loss.\n",
    "        - **4 x 4 x 512** Tensor before the **Flatten** layer.\n",
    "        - **512** Dense layer with **ReLU** activation.\n",
    "        - **10** Dense output layer with **Softmax** activation.\n",
    "        - **Dropout** layers with **0.5** rate after the Flatten and Dense layers.\n",
    "        - **L2** regularization with **0.0001** rate on the Dense layers.\n",
    "    - **4 199 946** Trainable Parameters.\n",
    "    - **30 Epochs** to train the classifier.  \n",
    "- **Model Evaluation**."
   ],
   "id": "8f90eceeed232e54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Imports and Setup"
   ],
   "id": "c6735bde07639ba2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T13:53:36.382048Z",
     "start_time": "2024-06-08T13:53:34.572958Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, optimizers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay ,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Group Datasets"
   ],
   "id": "3bd6072b1d12d0b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:53:39.379980Z",
     "start_time": "2024-06-08T13:53:39.377383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "train_dirs = [f'../data/train1_resized_{IMG_SIZE}', f'../data/train3_resized_{IMG_SIZE}', f'../data/train4_resized_{IMG_SIZE}', f'../data/train5_resized_{IMG_SIZE}']\n",
    "validation_dir = f'../data/train2_resized_{IMG_SIZE}'\n",
    "test_dir = f'../data/test_resized_{IMG_SIZE}'"
   ],
   "id": "f972b55051087b5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Create Datasets"
   ],
   "id": "dfc2bfc04e619b7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:53:48.681001Z",
     "start_time": "2024-06-08T13:53:44.466407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "train_datasets = [image_dataset_from_directory(directory, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE) for directory in train_dirs]\n",
    "\n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "class_names = train_datasets[0].class_names\n",
    "\n",
    "for data_batch, labels_batch in train_dataset.take(1):\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)"
   ],
   "id": "d699b2929af3e6b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "data batch shape: (64, 128, 128, 3)\n",
      "labels batch shape: (64,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We define the image size of 128 x 128 x 3, batch size of 64 and create an array with the label's names.  \n",
    "- We create the train dataset by concatenating them, we **shuffle** the samples before each epoch and **prefetch** them to memory.  \n",
    "- We do the same for the validation and test dataset except **shuffling** which is **unwanted** for these datasets."
   ],
   "id": "d7988a1b1bf91e80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Arquitecture"
   ],
   "id": "e1295d3f549e2bcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:58:03.511636Z",
     "start_time": "2024-06-08T13:54:29.879570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.models.load_model('../models/06_model_t_tl_feat_ext_data_augm_adam.h5')\n",
    "model.summary()"
   ],
   "id": "8d759c46781d034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 213s 1s/step - loss: 0.4563 - accuracy: 0.8996\n",
      "val_acc: 0.8996000289916992\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ],
   "id": "d02fb7488676f1e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T13:58:11.266501Z",
     "start_time": "2024-06-08T13:58:11.261947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convbase = model.get_layer(\"vgg16\")\n",
    "convbase.trainable = True\n",
    "for layer in convbase.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for i, layer in enumerate(convbase.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ],
   "id": "e02a4faa4379f6a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Compilation"
   ],
   "id": "b91ca83987f82a9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "initial_learning_rate = 0.0001\n",
    "optimizer = optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
    "save_best_model = callbacks.ModelCheckpoint(filepath='../models/07_model_t_tl_fine_tune_data_augm_adam.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, early_stopping, save_best_model]\n",
    "\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ],
   "id": "6a604147d46665f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Training"
   ],
   "id": "1561b6b62a6a19e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ],
   "id": "7c7803fd68bb2466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Save Model History"
   ],
   "id": "c1414fc4bf4495f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"../history/07_model_t_tl_fine_tune_data_augm_adam.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "id": "f5ee8f1b7a93d59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Evaluation"
   ],
   "id": "75ab7a00cecd12d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print(f'Classifier Validation Loss: {val_loss:.2f}')\n",
    "print(f'Classifier Validation Accuracy: {val_acc:.2%}')"
   ],
   "id": "119ca4b48e11020d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Visualization"
   ],
   "id": "3e06235a110145b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b82798d66c269136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Analyzing the training and validation, accuracy and loss over the epochs:\n",
    "    - We see that the model begins overfitting slightly after the **24th** epoch.\n",
    "    - The validation accuracy stops improving significantly after the **26th** epoch while the training accuracy keeps improving.\n",
    "    - The validation loss stops improving significantly after the **24th** epoch while the training loss keeps improving.\n",
    "    - The best model, based on validation loss, is saved on the **29th** epoch.   "
   ],
   "id": "3b28b2e5a426f333"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Testing"
   ],
   "id": "d2409d0121f3719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels = []\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    test_labels.extend(labels.numpy())\n",
    "    predictions = model.predict(images)\n",
    "    test_predictions.extend(np.argmax(predictions, axis=-1))\n",
    "    test_probabilities.extend(predictions)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_probabilities = np.array(test_probabilities)"
   ],
   "id": "85b3f7b2aa7331fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Confusion Matrix"
   ],
   "id": "fca30daa6d2c5258"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.show()"
   ],
   "id": "4be6a931c81836a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the confusion matrix, we see that:  \n",
    "    - The model still has a hard time distinguishing between the categories 003_cat and 005_dog but with less error.  \n",
    "    - The model has a below average performance on the categories 003_cat, 005_dog and 002_bird, in which we see a very high false positive rate.\n",
    "    - The model also has a hard time distinguishing between some other categories but the error is not as significant.  \n",
    "    - The model has an above average performance on the categories 001_automobile, 006_frog, 008_ship and 009_truck.\n",
    "    - The model has shown a performance increase with higher accuracy across all categories."
   ],
   "id": "8a3e816c5c8fe13a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### ROC Curve Analysis"
   ],
   "id": "e68c9fb0e696ac86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels_bin = label_binarize(test_labels, classes=range(NUM_CLASSES))\n",
    "\n",
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    false_positive_rate[i], true_positive_rate[i], _ = roc_curve(test_labels_bin[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(false_positive_rate[i], true_positive_rate[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'brown', 'pink', 'grey'])\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(false_positive_rate[i], true_positive_rate[i], color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "b8f0a28c2c459ae9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the ROC curve:\n",
    "    - We see that the model has a good performance on the ROC curve for most categories.  \n",
    "    - The categories 003_cat, 002_bird and 005_dog have the worst AUC (Area Under Curve) performance.\n",
    "    - The other categories have the same performance but with higher AUC.\n",
    "    - The category 001_automobile, 008_ship and 009_truck has the best AUC performance.\n",
    "    - The overall AUC performance increases as the false positive rate decreases and the true positive rate increases.\n",
    "    - **A perfect AUC of 1.0 would mean that the model classifies all images either true positives or true negatives**."
   ],
   "id": "713c306fcd31d921"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Performance Metrics\n",
    "- **Accuracy** is the proportion of correctly predicted instances out of the total instances.  \n",
    "- **Precision** is the ratio of true positive predictions to the total predicted positives. Macro precision calculates this for each class independently and then averages them.  \n",
    "- **Weighted precision** calculates the precision for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- **Recall** is the ratio of true positive predictions to the total actual positives. Macro recall calculates this for each class independently and then averages them.  \n",
    "- **Weighted recall** calculates the recall for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- The **F1-score** is the harmonic mean of precision and recall. Macro F1-score calculates this for each class independently and then averages them.  \n",
    "- **Weighted F1-score** calculates the F1-score for each class, then averages them, weighted by the number of true instances for each class.  "
   ],
   "id": "e8c8ee6e74938bdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = accuracy_score(y_true =  test_labels, y_pred = test_predictions)\n",
    "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Precision - Macro: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Recall - Macro: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'F1-score - Macro: {np.round(f1*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Precision - Weighted: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Recall - Weighted: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'F1-score - Weighted: {np.round(f1*100,2)}%')"
   ],
   "id": "479b290df6a7c03b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- **Since the dataset is balanced, the **MACRO** average is a good metric to evaluate the model.**",
   "id": "a153655cd9046d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "### Summary\n",
    "- Before this notebook:\n",
    "    - We resized our images to be the 128 x 128 x 3.\n",
    "    - Our reasoning was up scaling by a factor of 4.\n",
    "\n",
    "- In this notebook:\n",
    "    - We extracted feature maps from our train and validation datasets using the convolutional base of the VGG16.\n",
    "    - We trained a classifier with those extracted features:\n",
    "        - We used the Root Mean Squared Propagation (RMSProp) optimizer with an initial learning rate of 0.001.\n",
    "        - We kept the same 30 epochs.\n",
    "        - We evaluated the classifier. \n",
    "        - Overfitting was observed after **15 epochs**, but the best classifier was saved at the **20th epoch**.\n",
    "    - We then joined the VGG16 Convolutional Base with our Classifier\n",
    "    - We tested the resulting model\n",
    "        - The model showed some difficulty distinguishing between certain categories, particularly cats and dogs.\n",
    "        - Overfitting was observed after **15 epochs**, but the best model was saved at the **20th epoch**.\n",
    "        - We evaluated the model using a confusion matrix to analyze its performance on each category.\n",
    "        - We evaluated the model using ROC curves for a deeper performance analysis.\n",
    "        - **The model achieved an accuracy of 81.83% on the test set**.\n",
    "    - Performance on the test set was good, with:\n",
    "        - Macro F1-score: 89.29%\n",
    "        - Weighted F1-score: 89.29%\n",
    "        - Macro precision: 89.32%\n",
    "        - Weighted precision: 89.32%\n",
    "        - Macro recall: 89.29%\n",
    "        - Weighted recall: 89.29%\n",
    "\n",
    "### Future Work\n",
    "- In the next notebook:\n",
    "    - Implement and train a transfer learning model with the VGG16 convolutional base frozen and a new classifier.\n",
    "    - Experiment with data augmentation to improve classifier generalization.\n",
    "    - Test the model performance."
   ],
   "id": "9d23124cf3831d1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
