{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f90eceeed232e54",
   "metadata": {},
   "source": [
    "---\n",
    "# Model S - Deepened, Widened, Enhanced with Adaptive Moment Estimation (Adam)\n",
    "- **32 x 32 x 3** Image size.\n",
    "- **64** Batch size.\n",
    "- Adaptive Moment Estimation **(Adam)** optimizer.\n",
    "- **0.001** Initial Learning rate.\n",
    "- **Sparse Categorical Cross-Entropy** loss function.\n",
    "- **Reduce Learning Rate on Plateau** callback.\n",
    "- **Early Stopping** callback.\n",
    "- **Model Checkpoint** callback.\n",
    "- 4 **Convolutional** layers with **32**, **64**, **128** and **256** filters, with **ReLU** activation.\n",
    "- 4 **BatchNormalization** layers.\n",
    "- 2 **MaxPooling** layers with **2 x 2** pool size.\n",
    "- **3 x 3** Convolutional kernel size.\n",
    "- **5 x 5 x 256** Tensor before flatten.\n",
    "- **512** Dense layer with **ReLU** activation.\n",
    "- **10** Dense output layer with **Softmax** activation.\n",
    "- **0.5** Dropout rate on Dense layers.\n",
    "- **3 672 778** Trainable Parameters\n",
    "- **30** Epochs."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Imports and Setup"
   ],
   "id": "ce76e06a33cd2f04"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T01:29:35.003013Z",
     "start_time": "2024-06-06T01:29:32.993766Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, models, regularizers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay ,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3bd6072b1d12d0b4",
   "metadata": {},
   "source": [
    "---\n",
    "#### Group Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "f972b55051087b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:29:35.006972Z",
     "start_time": "2024-06-06T01:29:35.004592Z"
    }
   },
   "source": [
    "train_dirs = ['../data/train1', '../data/train3', '../data/train4', '../data/train5']\n",
    "validation_dir = '../data/train2'\n",
    "test_dir = '../data/test'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "dfc2bfc04e619b7d",
   "metadata": {},
   "source": [
    "---\n",
    "#### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "d699b2929af3e6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:29:37.079813Z",
     "start_time": "2024-06-06T01:29:35.007832Z"
    }
   },
   "source": [
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "train_datasets = [image_dataset_from_directory(directory, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE) for directory in train_dirs]\n",
    "\n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "class_names = train_datasets[0].class_names\n",
    "\n",
    "for data_batch, labels_batch in train_dataset.take(1):\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "data batch shape: (64, 32, 32, 3)\n",
      "labels batch shape: (64,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3e9a6a77",
   "metadata": {},
   "source": [
    "- We define the image size of 32 x 32 x 3, batch size of 64 and create an array with the label's names.  \n",
    "- We create the train dataset by concatenating them, we **shuffle** the samples before each epoch and **prefetch** them to memory.  \n",
    "- We do the same for the validation and test dataset except **shuffling** which is **unwanted** for these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1295d3f549e2bcc",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "id": "83b92ce40cddb3b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:29:37.203179Z",
     "start_time": "2024-06-06T01:29:37.080647Z"
    }
   },
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 30, 30, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 28, 28, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 12, 12, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 10, 10, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3277312   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3672778 (14.01 MB)\n",
      "Trainable params: 3671818 (14.01 MB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b91ca83987f82a9c",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a604147d46665f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T01:29:37.215210Z",
     "start_time": "2024-06-06T01:29:37.204514Z"
    }
   },
   "source": [
    "initial_learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
    "save_best_model = callbacks.ModelCheckpoint(filepath='../models/02_model_s_deepen_widen_enhance_adam.keras', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, early_stopping, save_best_model]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "1561b6b62a6a19e8",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c7803fd68bb2466",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-06T01:29:37.215934Z"
    }
   },
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=30,\n",
    "                    callbacks=callbacks)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 1.7375 - accuracy: 0.4203\n",
      "Epoch 1: val_loss improved from inf to 1.66406, saving model to ../models/02_model_s_deepen_widen_enhance_adam.keras\n",
      "628/628 [==============================] - 72s 112ms/step - loss: 1.7375 - accuracy: 0.4203 - val_loss: 1.6641 - val_accuracy: 0.3948 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 1.2157 - accuracy: 0.5731\n",
      "Epoch 2: val_loss improved from 1.66406 to 1.06504, saving model to ../models/02_model_s_deepen_widen_enhance_adam.keras\n",
      "628/628 [==============================] - 73s 116ms/step - loss: 1.2157 - accuracy: 0.5731 - val_loss: 1.0650 - val_accuracy: 0.6360 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 1.0548 - accuracy: 0.6335\n",
      "Epoch 3: val_loss did not improve from 1.06504\n",
      "628/628 [==============================] - 73s 116ms/step - loss: 1.0548 - accuracy: 0.6335 - val_loss: 1.0684 - val_accuracy: 0.6249 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.9550 - accuracy: 0.6710\n",
      "Epoch 4: val_loss improved from 1.06504 to 0.91880, saving model to ../models/02_model_s_deepen_widen_enhance_adam.keras\n",
      "628/628 [==============================] - 75s 119ms/step - loss: 0.9550 - accuracy: 0.6710 - val_loss: 0.9188 - val_accuracy: 0.6875 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.8699 - accuracy: 0.7009\n",
      "Epoch 5: val_loss did not improve from 0.91880\n",
      "628/628 [==============================] - 71s 113ms/step - loss: 0.8699 - accuracy: 0.7009 - val_loss: 0.9826 - val_accuracy: 0.6757 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.7250\n",
      "Epoch 6: val_loss improved from 0.91880 to 0.88015, saving model to ../models/02_model_s_deepen_widen_enhance_adam.keras\n",
      "628/628 [==============================] - 74s 117ms/step - loss: 0.8011 - accuracy: 0.7250 - val_loss: 0.8802 - val_accuracy: 0.7010 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.7408\n",
      "Epoch 7: val_loss improved from 0.88015 to 0.76338, saving model to ../models/02_model_s_deepen_widen_enhance_adam.keras\n",
      "628/628 [==============================] - 73s 116ms/step - loss: 0.7546 - accuracy: 0.7408 - val_loss: 0.7634 - val_accuracy: 0.7452 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "390/628 [=================>............] - ETA: 24s - loss: 0.6936 - accuracy: 0.7615"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "85d8e1568d50c001",
   "metadata": {},
   "source": [
    "---\n",
    "#### Save Model History"
   ]
  },
  {
   "cell_type": "code",
   "id": "415ebc4991342988",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "with open(\"../history/02_model_s_deepen_widen_enhance_adam.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6c9a3be5bef27854",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "c57eaf5c0f9e6010",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print(f'Model Validation Loss: {val_loss:.2f}')\n",
    "print(f'Model Validation Accuracy: {val_acc:.2%}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e06235a110145b5",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "id": "b82798d66c269136",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Analyzing the training and validation, accuracy and loss over the epochs:\n",
    "    - We see that the model begins overfitting after the **4th** epoch.\n",
    "    - The training accuracy stops improving significantly after the **11th** epoch while the training accuracy keeps improving.\n",
    "    - The validation loss stops improving significantly after the **11th** epoch while the training loss keeps improving.\n",
    "    - The best model, based on validation loss, is saved on the **16th** epoch.\n",
    "    - The training stops after the **20th** epoch because of the **Early Stopping** callback."
   ],
   "id": "c16a851b80b27662"
  },
  {
   "cell_type": "markdown",
   "id": "d2409d0121f3719",
   "metadata": {},
   "source": [
    "---\n",
    "#### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "85b3f7b2aa7331fb",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "test_labels = []\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    test_labels.extend(labels.numpy())\n",
    "    predictions = model.predict(images)\n",
    "    test_predictions.extend(np.argmax(predictions, axis=-1))\n",
    "    test_probabilities.extend(predictions)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_probabilities = np.array(test_probabilities)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fca30daa6d2c5258",
   "metadata": {},
   "source": [
    "---\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "4be6a931c81836a8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the confusion matrix, we see that:  \n",
    "    - The model has a hard time distinguishing the categories 003_cat and 005_dog.  \n",
    "    - The model has a below average performance on the categories 003_cat, 005_dog, 002_bird and 004_deer, in which we see a very high false positive rate.\n",
    "    - The model also has a hard time distinguishing between some other categories but the error is not as significant.  \n",
    "    - The model has an above average performance on the categories 001_automobile, 006_frog, 008_ship and 009_truck.\n",
    "    - Basically, the model has the same performance but with higher accuracy."
   ],
   "id": "d8205b94155b52c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### ROC Curve Analysis"
   ],
   "id": "d575d3b176d44ac6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "test_labels_bin = label_binarize(test_labels, classes=range(NUM_CLASSES))\n",
    "\n",
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    false_positive_rate[i], true_positive_rate[i], _ = roc_curve(test_labels_bin[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(false_positive_rate[i], true_positive_rate[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'brown', 'pink', 'grey'])\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(false_positive_rate[i], true_positive_rate[i], color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "8f0afe1b3635853b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the ROC curve:\n",
    "    - We see that the model has a mediocre performance on the ROC curve for most categories.  \n",
    "    - The categories 003_cat, 002_bird, 005_dog and 004_deer have the worst AUC (Area Under Curve) performance.\n",
    "    - The other categories have the same performance but with higher AUC.\n",
    "    - The category 001_automobile has the best AUC performance.\n",
    "    - The overall AUC performance increases as the false positive rate decreases and the true positive rate increases.\n",
    "    - **A perfect AUC of 1.0 would mean that the model classifies all images either true positives or true negatives**."
   ],
   "id": "e9735c5593d108fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Performance Metrics\n",
    "- **Accuracy** is the proportion of correctly predicted instances out of the total instances.  \n",
    "- **Precision** is the ratio of true positive predictions to the total predicted positives. Macro precision calculates this for each class independently and then averages them.  \n",
    "- **Weighted precision** calculates the precision for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- **Recall** is the ratio of true positive predictions to the total actual positives. Macro recall calculates this for each class independently and then averages them.  \n",
    "- **Weighted recall** calculates the recall for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- The **F1-score** is the harmonic mean of precision and recall. Macro F1-score calculates this for each class independently and then averages them.  \n",
    "- **Weighted F1-score** calculates the F1-score for each class, then averages them, weighted by the number of true instances for each class."
   ],
   "id": "c7b47659cd8deced"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "acc = accuracy_score(y_true =  test_labels, y_pred = test_predictions)\n",
    "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Precision - Macro: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Recall - Macro: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'F1-score - Macro: {np.round(f1*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Precision - Weighted: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Recall - Weighted: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'F1-score - Weighted: {np.round(f1*100,2)}%')"
   ],
   "id": "e54dd1cb229304a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- **Since the dataset is balanced, the **MACRO** average is a good metric to evaluate the model.**",
   "id": "d1f70d1d4637bb4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "### Summary\n",
    "- In this notebook:\n",
    "    - We deepened, widened and enhanced the architecture by:\n",
    "        - We added 2 more convolutional layers.\n",
    "        - We used a 512 unit dense layer.\n",
    "        - We added batch normalization after each convolution.\n",
    "    - We used the Adaptive Moment Estimation (Adam) optimizer.\n",
    "    - We kept the same 30 epochs.                                                          - \n",
    "    - Overfitting was observed after **12 epochs**, but the best model was saved at the **20th epoch**.\n",
    "    - Training was intended for 30 epochs but stopped early due to the **Early Stopping** callback.\n",
    "    - We evaluated the model using a confusion matrix to analyze its performance on each category.\n",
    "    - We evaluated the model using ROC curves for a deeper performance analysis.\n",
    "    - The model achieved an accuracy of **70.87%** on the test set.\n",
    "    - The model showed some difficulty distinguishing between certain categories, particularly cats and dogs.\n",
    "    - The model showed a below average performance on the categories birds and deer.\n",
    "    - The model showed an above average performance on the categories automobile, frog, ship and truck.\n",
    "\n",
    "### Future Work\n",
    "- In the next notebook:\n",
    "    - We will implement a few measures to improve the model's performance:\n",
    "        - We will use data augmentation techniques.\n",
    "        - We will use L1 and L2 regularization.\n",
    "    - We will use the Root Mean Squared Propagation (RMSProp) optimizer.\n",
    "    - We will keep the same 30 epochs."
   ],
   "id": "96bc06a924010390"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
