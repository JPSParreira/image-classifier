{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Model T - Transfer Learning, Feature Extraction, Data Augmentation, Adaptive Moment Estimation (Adam)\n",
    "- **128 x 128 x 3** Image size.  \n",
    "- **64** Batch size.\n",
    "- Build the **full model** with **VGG16** convolutional base and a **Classifier** and **Train it**.\n",
    "    - **Data Augmentation Pipeline**\n",
    "        - Random **Horizontal** Flip\n",
    "        - Random Rotation **5%**\n",
    "        - Random Zoom **5%**\n",
    "        - Random Contrast **5%**\n",
    "        - Random Brightness **5%**\n",
    "    - **Feature Extraction**.\n",
    "        - **VGG16** Convolutional Base **(Frozen)**.\n",
    "        - **4 x 4 x 512** Feature Maps.\n",
    "    - **Classifier**: \n",
    "        - Adaptive Moment Estimation **(Adam)** optimizer.\n",
    "        - **0.001** Initial Learning rate.\n",
    "        - **Sparse Categorical Cross-Entropy** loss function.\n",
    "        - **Reduce Learning Rate on Plateau** callback with a **0.1** factor and **3** patience.\n",
    "        - **Early Stopping** callback with **6** patience.\n",
    "        - **Model Checkpoint** callback to save the best model based on validation loss.\n",
    "        - **4 x 4 x 512** Tensor before the **Flatten** layer.\n",
    "        - **512** Dense layer with **ReLU** activation.\n",
    "        - **10** Dense output layer with **Softmax** activation.\n",
    "        - **Dropout** layers with **0.5** rate after the Flatten and Dense layers.\n",
    "        - **L2** regularization with **0.0001** rate on the Dense layers.\n",
    "    - **4 199 946** Trainable Parameters.\n",
    "    - **30 Epochs**.  \n",
    "- **Model Evaluation**."
   ],
   "id": "8f90eceeed232e54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Imports and Setup"
   ],
   "id": "c6735bde07639ba2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:18.558339Z",
     "start_time": "2024-06-08T14:06:15.527617Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks, layers, optimizers\n",
    "from keras import regularizers, Model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay ,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Group Datasets"
   ],
   "id": "3bd6072b1d12d0b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:18.562375Z",
     "start_time": "2024-06-08T14:06:18.559727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_SIZE = 128\n",
    "\n",
    "train_dirs = [f'../data/train1_resized_{IMG_SIZE}', f'../data/train3_resized_{IMG_SIZE}', f'../data/train4_resized_{IMG_SIZE}', f'../data/train5_resized_{IMG_SIZE}']\n",
    "validation_dir = f'../data/train2_resized_{IMG_SIZE}'\n",
    "test_dir = f'../data/test_resized_{IMG_SIZE}'"
   ],
   "id": "f972b55051087b5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Create Datasets"
   ],
   "id": "dfc2bfc04e619b7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:23.176122Z",
     "start_time": "2024-06-08T14:06:18.563314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "train_datasets = [image_dataset_from_directory(directory, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE) for directory in train_dirs]\n",
    "\n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "class_names = train_datasets[0].class_names\n",
    "\n",
    "for data_batch, labels_batch in train_dataset.take(1):\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)"
   ],
   "id": "d699b2929af3e6b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "data batch shape: (64, 128, 128, 3)\n",
      "labels batch shape: (64,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- We define the image size of 128 x 128 x 3, batch size of 64 and create an array with the label's names.  \n",
    "- We create the train dataset by concatenating them, we **shuffle** the samples before each epoch and **prefetch** them to memory.  \n",
    "- We do the same for the validation and test dataset except **shuffling** which is **unwanted** for these datasets."
   ],
   "id": "d7988a1b1bf91e80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Data Augmentation Pipeline"
   ],
   "id": "263c5de76a96c518"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:23.193508Z",
     "start_time": "2024-06-08T14:06:23.177226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        # keras.layers.RandomCrop(height=16, width=16), # This layer is commented out because it is not compatible with the current model architecture.\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        # keras.layers.RandomTranslation(0.1, 0.1), # This layer is commented out because it didn't improve the model performance.\n",
    "        keras.layers.RandomRotation(0.05),\n",
    "        keras.layers.RandomZoom(0.05),\n",
    "        keras.layers.RandomContrast(0.05),\n",
    "        keras.layers.RandomBrightness(0.05),\n",
    "    ]\n",
    ")"
   ],
   "id": "db303102e19eb9d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Loading the VGG16 Model"
   ],
   "id": "d1a35d3cdfbf44a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:26.156448Z",
     "start_time": "2024-06-08T14:06:23.194947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False)\n",
    "conv_base.trainable = False\n",
    "conv_base.summary()"
   ],
   "id": "7cea8386294502c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Arquitecture"
   ],
   "id": "e1295d3f549e2bcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:26.450942Z",
     "start_time": "2024-06-08T14:06:26.157252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.L2(1e-4))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", kernel_regularizer=regularizers.L2(1e-4))(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ],
   "id": "83b92ce40cddb3b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (  (None, 128, 128, 3)       0         \n",
      " SlicingOpLambda)                                                \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda  (None, 128, 128, 3)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               4194816   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18914634 (72.15 MB)\n",
      "Trainable params: 4199946 (16.02 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Compilation"
   ],
   "id": "b91ca83987f82a9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T14:06:26.463084Z",
     "start_time": "2024-06-08T14:06:26.451755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_learning_rate = 0.001\n",
    "optimizer = optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "loss_function = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
    "save_best_model = callbacks.ModelCheckpoint(filepath='../models/06_model_t_tl_data_augm_adam.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, early_stopping, save_best_model]\n",
    "\n",
    "model.compile(\n",
    "    loss=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"])"
   ],
   "id": "6a604147d46665f1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Training"
   ],
   "id": "1561b6b62a6a19e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T17:04:20.802698Z",
     "start_time": "2024-06-08T14:06:26.463833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ],
   "id": "7c7803fd68bb2466",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 1.8821 - accuracy: 0.6627\n",
      "Epoch 1: val_loss improved from inf to 0.68523, saving model to ../models/06_model_t_tl_feat_ext_data_augm_adam.h5\n",
      "628/628 [==============================] - 1094s 2s/step - loss: 1.8821 - accuracy: 0.6627 - val_loss: 0.6852 - val_accuracy: 0.8186 - lr: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628/628 [==============================] - ETA: 0s - loss: 0.9957 - accuracy: 0.7320\n",
      "Epoch 2: val_loss improved from 0.68523 to 0.61996, saving model to ../models/06_model_t_tl_feat_ext_data_augm_adam.h5\n",
      "628/628 [==============================] - 1095s 2s/step - loss: 0.9957 - accuracy: 0.7320 - val_loss: 0.6200 - val_accuracy: 0.8482 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.9141 - accuracy: 0.7627\n",
      "Epoch 3: val_loss improved from 0.61996 to 0.60610, saving model to ../models/06_model_t_tl_feat_ext_data_augm_adam.h5\n",
      "628/628 [==============================] - 1094s 2s/step - loss: 0.9141 - accuracy: 0.7627 - val_loss: 0.6061 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.7789\n",
      "Epoch 4: val_loss did not improve from 0.60610\n",
      "628/628 [==============================] - 1094s 2s/step - loss: 0.9045 - accuracy: 0.7789 - val_loss: 0.6262 - val_accuracy: 0.8643 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.7843\n",
      "Epoch 5: val_loss did not improve from 0.60610\n",
      "628/628 [==============================] - 1094s 2s/step - loss: 0.9092 - accuracy: 0.7843 - val_loss: 0.6588 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.9112 - accuracy: 0.7896\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.60610\n",
      "628/628 [==============================] - 1093s 2s/step - loss: 0.9112 - accuracy: 0.7896 - val_loss: 0.6571 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.8168 - accuracy: 0.8160\n",
      "Epoch 7: val_loss did not improve from 0.60610\n",
      "628/628 [==============================] - 1092s 2s/step - loss: 0.8168 - accuracy: 0.8160 - val_loss: 0.6215 - val_accuracy: 0.8792 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.7753 - accuracy: 0.8259\n",
      "Epoch 8: val_loss did not improve from 0.60610\n",
      "628/628 [==============================] - 1092s 2s/step - loss: 0.7753 - accuracy: 0.8259 - val_loss: 0.6061 - val_accuracy: 0.8832 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "628/628 [==============================] - ETA: 0s - loss: 0.7502 - accuracy: 0.8330\n",
      "Epoch 9: val_loss improved from 0.60610 to 0.59534, saving model to ../models/06_model_t_tl_feat_ext_data_augm_adam.h5\n",
      "628/628 [==============================] - 1093s 2s/step - loss: 0.7502 - accuracy: 0.8330 - val_loss: 0.5953 - val_accuracy: 0.8827 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "595/628 [===========================>..] - ETA: 46s - loss: 0.7297 - accuracy: 0.8352"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Save Model History"
   ],
   "id": "c1414fc4bf4495f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(\"../history/06_model_t_tl_data_augm_adam.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "id": "f5ee8f1b7a93d59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Evaluation"
   ],
   "id": "75ab7a00cecd12d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print(f'Classifier Validation Loss: {val_loss:.2f}')\n",
    "print(f'Classifier Validation Accuracy: {val_acc:.2%}')"
   ],
   "id": "119ca4b48e11020d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Visualization"
   ],
   "id": "3e06235a110145b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b82798d66c269136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Analyzing the training and validation, accuracy and loss over the epochs:\n",
    "    - We see that the model begins overfitting slightly after the **24th** epoch.\n",
    "    - The validation accuracy stops improving significantly after the **26th** epoch while the training accuracy keeps improving.\n",
    "    - The validation loss stops improving significantly after the **24th** epoch while the training loss keeps improving.\n",
    "    - The best model, based on validation loss, is saved on the **29th** epoch.   "
   ],
   "id": "3b28b2e5a426f333"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Model Testing"
   ],
   "id": "d2409d0121f3719"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels = []\n",
    "test_predictions = []\n",
    "test_probabilities = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    test_labels.extend(labels.numpy())\n",
    "    predictions = model.predict(images)\n",
    "    test_predictions.extend(np.argmax(predictions, axis=-1))\n",
    "    test_probabilities.extend(predictions)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_probabilities = np.array(test_probabilities)"
   ],
   "id": "85b3f7b2aa7331fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Confusion Matrix"
   ],
   "id": "fca30daa6d2c5258"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=90)\n",
    "plt.show()"
   ],
   "id": "4be6a931c81836a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the confusion matrix, we see that:  \n",
    "    - The model still has a hard time distinguishing between the categories 003_cat and 005_dog but with less error.  \n",
    "    - The model has a below average performance on the categories 003_cat, 005_dog and 002_bird, in which we see a very high false positive rate.\n",
    "    - The model also has a hard time distinguishing between some other categories but the error is not as significant.  \n",
    "    - The model has an above average performance on the categories 001_automobile, 006_frog, 008_ship and 009_truck.\n",
    "    - The model has shown a performance increase with higher accuracy across all categories."
   ],
   "id": "8a3e816c5c8fe13a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### ROC Curve Analysis"
   ],
   "id": "e68c9fb0e696ac86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_labels_bin = label_binarize(test_labels, classes=range(NUM_CLASSES))\n",
    "\n",
    "false_positive_rate = dict()\n",
    "true_positive_rate = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "    false_positive_rate[i], true_positive_rate[i], _ = roc_curve(test_labels_bin[:, i], test_probabilities[:, i])\n",
    "    roc_auc[i] = auc(false_positive_rate[i], true_positive_rate[i])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'blue', 'green', 'red', 'purple', 'brown', 'pink', 'grey'])\n",
    "for i, color in zip(range(NUM_CLASSES), colors):\n",
    "    plt.plot(false_positive_rate[i], true_positive_rate[i], color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "b8f0a28c2c459ae9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Looking at the ROC curve:\n",
    "    - We see that the model has a good performance on the ROC curve for most categories.  \n",
    "    - The categories 003_cat, 002_bird and 005_dog have the worst AUC (Area Under Curve) performance.\n",
    "    - The other categories have the same performance but with higher AUC.\n",
    "    - The category 001_automobile, 008_ship and 009_truck has the best AUC performance.\n",
    "    - The overall AUC performance increases as the false positive rate decreases and the true positive rate increases.\n",
    "    - **A perfect AUC of 1.0 would mean that the model classifies all images either true positives or true negatives**."
   ],
   "id": "713c306fcd31d921"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Performance Metrics\n",
    "- **Accuracy** is the proportion of correctly predicted instances out of the total instances.  \n",
    "- **Precision** is the ratio of true positive predictions to the total predicted positives. Macro precision calculates this for each class independently and then averages them.  \n",
    "- **Weighted precision** calculates the precision for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- **Recall** is the ratio of true positive predictions to the total actual positives. Macro recall calculates this for each class independently and then averages them.  \n",
    "- **Weighted recall** calculates the recall for each class, then averages them, weighted by the number of true instances for each class.  \n",
    "- The **F1-score** is the harmonic mean of precision and recall. Macro F1-score calculates this for each class independently and then averages them.  \n",
    "- **Weighted F1-score** calculates the F1-score for each class, then averages them, weighted by the number of true instances for each class.  "
   ],
   "id": "e8c8ee6e74938bdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "acc = accuracy_score(y_true =  test_labels, y_pred = test_predictions)\n",
    "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Precision - Macro: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'Recall - Macro: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='macro')\n",
    "print(f'F1-score - Macro: {np.round(f1*100,2)}%')\n",
    "precision = precision_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Precision - Weighted: {np.round(precision*100,2)}%')\n",
    "recall = recall_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'Recall - Weighted: {np.round(recall*100,2)}%')\n",
    "f1 = f1_score(y_true =  test_labels, y_pred = test_predictions, average='weighted')\n",
    "print(f'F1-score - Weighted: {np.round(f1*100,2)}%')"
   ],
   "id": "479b290df6a7c03b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- **Since the dataset is balanced, the **MACRO** average is a good metric to evaluate the model.**",
   "id": "a153655cd9046d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "### Summary\n",
    "- Before this notebook:\n",
    "    - We resized our images to be the 128 x 128 x 3.\n",
    "    - Our reasoning was up scaling by a factor of 4.\n",
    "\n",
    "- In this notebook:\n",
    "    - We extracted feature maps from our train and validation datasets using the convolutional base of the VGG16.\n",
    "    - We trained a classifier with those extracted features:\n",
    "        - We used the Root Mean Squared Propagation (RMSProp) optimizer with an initial learning rate of 0.001.\n",
    "        - We kept the same 30 epochs.\n",
    "        - We evaluated the classifier. \n",
    "        - Overfitting was observed after **15 epochs**, but the best classifier was saved at the **20th epoch**.\n",
    "    - We then joined the VGG16 Convolutional Base with our Classifier\n",
    "    - We tested the resulting model\n",
    "        - The model showed some difficulty distinguishing between certain categories, particularly cats and dogs.\n",
    "        - Overfitting was observed after **15 epochs**, but the best model was saved at the **20th epoch**.\n",
    "        - We evaluated the model using a confusion matrix to analyze its performance on each category.\n",
    "        - We evaluated the model using ROC curves for a deeper performance analysis.\n",
    "        - **The model achieved an accuracy of 81.83% on the test set**.\n",
    "    - Performance on the test set was good, with:\n",
    "        - Macro F1-score: 89.29%\n",
    "        - Weighted F1-score: 89.29%\n",
    "        - Macro precision: 89.32%\n",
    "        - Weighted precision: 89.32%\n",
    "        - Macro recall: 89.29%\n",
    "        - Weighted recall: 89.29%\n",
    "\n",
    "### Future Work\n",
    "- In the next notebook:\n",
    "    - Implement and train a transfer learning model with the VGG16 convolutional base frozen and a new classifier.\n",
    "    - Experiment with data augmentation to improve classifier generalization.\n",
    "    - Test the model performance."
   ],
   "id": "9d23124cf3831d1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
